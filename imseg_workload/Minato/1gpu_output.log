STARTING TIMING RUN AT 2025-04-15 08:16:58 PM
:::MLLOG {"namespace": "", "time_ms": 1744748220358, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
2.4.1+cu121
:::MLLOG {"namespace": "", "time_ms": 1744748227178, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/main.py", "lineno": 83}}
Format conversion /raw_data
Distributed initialized. World size: 1
:::MLLOG {"namespace": "", "time_ms": 1744748227824, "event_type": "POINT_IN_TIME", "key": "world_size", "value": 1, "metadata": {"file": "/workspace/main.py", "lineno": 98}}
:::MLLOG {"namespace": "", "time_ms": 1744748227825, "event_type": "POINT_IN_TIME", "key": "local_rank", "value": 0, "metadata": {"file": "/workspace/main.py", "lineno": 99}}
:::MLLOG {"namespace": "", "time_ms": 1744748227825, "event_type": "POINT_IN_TIME", "key": "Batch size used", "value": 2, "metadata": {"file": "/workspace/main.py", "lineno": 100}}
:::MLLOG {"namespace": "", "time_ms": 1744748227825, "event_type": "POINT_IN_TIME", "key": "Epochs", "value": 50, "metadata": {"file": "/workspace/main.py", "lineno": 101}}
Using random master seed: 2685437364
:::MLLOG {"namespace": "", "time_ms": 1744748227827, "event_type": "POINT_IN_TIME", "key": "seed", "value": 856548860, "metadata": {"file": "/workspace/main.py", "lineno": 106}}
:::MLLOG {"namespace": "", "time_ms": 1744748227827, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 64}}
:::MLLOG {"namespace": "", "time_ms": 1744748227916, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "your-company", "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 69}}
:::MLLOG {"namespace": "", "time_ms": 1744748227916, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1744748227916, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1744748227916, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "your_platform", "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 81}}
:::MLLOG {"namespace": "", "time_ms": 1744748227916, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "sgd", "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 87}}
:::MLLOG {"namespace": "", "time_ms": 1744748227917, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.8, "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 88}}
:::MLLOG {"namespace": "", "time_ms": 1744748227917, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 10, "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 89}}
:::MLLOG {"namespace": "", "time_ms": 1744748227917, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 91}}
:::MLLOG {"namespace": "", "time_ms": 1744748227917, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 92}}
:::MLLOG {"namespace": "", "time_ms": 1744748227917, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 93}}
:::MLLOG {"namespace": "", "time_ms": 1744748227917, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1744748227917, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 95}}
:::MLLOG {"namespace": "", "time_ms": 1744748227918, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 96}}
:::MLLOG {"namespace": "", "time_ms": 1744748227918, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 97}}
:::MLLOG {"namespace": "", "time_ms": 1744748227918, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 98}}
:::MLLOG {"namespace": "", "time_ms": 1744748227918, "event_type": "POINT_IN_TIME", "key": "Loader", "value": "pytorch", "metadata": {"file": "/workspace/runtime/logging.py", "lineno": 99}}
:::MLLOG {"namespace": "", "time_ms": 1744748228191, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/main.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1744748228191, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/main.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1744748228194, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 169, "metadata": {"file": "/workspace/data_loading/data_loader.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1744748228195, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 41, "metadata": {"file": "/workspace/data_loading/data_loader.py", "lineno": 64}}
GPU Rank 0 is assigned 169 samples.
Created queue for GPU Rank 0.
[GPU Rank 0] Producer 0 assigned indices: [101, 93, 76, 91, 41, 158, 49, 137, 135, 69, 161, 151, 110, 3, 25, 153, 67, 34, 54, 84, 148, 152, 40, 42, 167, 77, 65, 111, 38, 146, 122, 82, 2, 113, 138, 13, 6, 85, 24, 86, 78, 32]
[GPU Rank 0] Producer 1 assigned indices: [37, 163, 57, 17, 16, 22, 75, 166, 160, 102, 128, 1, 144, 83, 46, 26, 117, 73, 168, 0, 44, 162, 66, 136, 147, 127, 12, 132, 130, 52, 125, 29, 18, 150, 143, 142, 129, 149, 9, 134, 145, 14]
[GPU Rank 0 | Producer 1264] Starting.
[GPU Rank 0 | Producer 1264] Processing index 101
[GPU Rank 0] Producer 2 assigned indices: [157, 121, 45, 99, 74, 68, 33, 39, 120, 96, 88, 89, 7, 72, 139, 50, 100, 141, 116, 60, 154, 19, 5, 103, 105, 27, 81, 131, 109, 15, 62, 53, 104, 80, 10, 20, 59, 155, 92, 63, 58, 112]
[GPU Rank 0 | Producer 1265] Starting.
[GPU Rank 0 | Producer 1265] Processing index 37
[GPU Rank 0] Producer 3 assigned indices: [36, 61, 47, 97, 43, 51, 35, 8, 28, 126, 106, 164, 71, 108, 30, 119, 140, 11, 31, 48, 70, 94, 159, 124, 21, 115, 95, 165, 156, 79, 123, 4, 118, 64, 98, 107, 90, 133, 87, 114, 56, 23]
[GPU Rank 0 | Producer 1266] Starting.
[GPU Rank 0 | Producer 1266] Processing index 157
GPU Rank 0 is assigned 41 samples.
[GPU Rank 0 | Producer 1267] Starting.
[GPU Rank 0 | Producer 1267] Processing index 36
Created queue for GPU Rank 0.
[GPU Rank 0] Producer 0 assigned indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]
:::MLLOG {"namespace": "", "time_ms": 1744748228254, "event_type": "POINT_IN_TIME", "key": "len train_dataloader", "value": 84, "metadata": {"file": "/workspace/main.py", "lineno": 120}}
[GPU Rank 0 | Producer 1268] Starting.
[GPU Rank 0 | Producer 1268] Processing index 0
:::MLLOG {"namespace": "", "time_ms": 1744748228256, "event_type": "POINT_IN_TIME", "key": "len val_dataloader", "value": 41, "metadata": {"file": "/workspace/main.py", "lineno": 121}}
:::MLLOG {"namespace": "", "time_ms": 1744748228256, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 168, "metadata": {"file": "/workspace/main.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1744748228256, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 2, "metadata": {"file": "/workspace/main.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1744748228257, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/main.py", "lineno": 129}}
training starts here
[GPU Rank 0 | Producer 1267] Processing index 61
:::MLLOG {"namespace": "", "time_ms": 1744748228560, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/runtime/training.py", "lineno": 82, "first_epoch_num": 1, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1744748228560, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/runtime/training.py", "lineno": 84, "epoch_num": 1}}
Starting new epoch for rank: 0 queue size <bound method Queue.qsize of <multiprocessing.queues.Queue object at 0x7fcd44beed50>>
Batch processed: 0 for rank: 0 epoch batches: 84
Queue size for GPU 0: 0 samples
[GPU Rank 0 | Producer 1266] Processing index 121
[GPU Rank 0 | Producer 1264] Processing index 93
[GPU Rank 0 | Producer 1265] Processing index 163
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
Queue size for GPU 0: 0 samples
